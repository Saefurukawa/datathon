{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"datathon_train.csv\")\n",
    "\n",
    "def get_time(string):\n",
    "  return int(string[:2])\n",
    "dataset['DEP_TIME'] = dataset['DEP_TIME_BLK'].apply(get_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model \n",
    "        to generalize and improves the interpretability of the model.\n",
    "\n",
    "    Inputs: \n",
    "        x: features dataframe\n",
    "        threshold: features with correlations greater than this value are removed\n",
    "\n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Raleigh-Durham International'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m remove_collinear_features(dataset, \u001b[39m0.7\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m, in \u001b[0;36mremove_collinear_features\u001b[0;34m(x, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mObjective:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    Remove collinear features in a dataframe with a correlation coefficient\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m    dataframe that contains only the non-highly-collinear features\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Calculate the correlation matrix\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m corr_matrix \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mcorr()\n\u001b[1;32m     18\u001b[0m iters \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(corr_matrix\u001b[39m.\u001b[39mcolumns) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m drop_cols \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10052\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m  10053\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m> 10054\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m  10056\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10057\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1837\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1838\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1840\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/internals/managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1794\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1795\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Raleigh-Durham International'"
     ]
    }
   ],
   "source": [
    "remove_collinear_features(dataset, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "def clean_labels_encoder(list_of_labels, df):\n",
    "    for label in list_of_labels:\n",
    "        df[label] = le.fit_transform(df[label])\n",
    "    return df\n",
    "\n",
    "# clean the labels\n",
    "list_of_labels = ['CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT']\n",
    "dataset = clean_labels_encoder(list_of_labels, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEPARTING_AIRPORT</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>SEGMENT_NUMBER</th>\n",
       "      <th>CONCURRENT_FLIGHTS</th>\n",
       "      <th>MANUFACTURE_YEAR</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "      <th>CARRIER_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>PLANE_AGE</th>\n",
       "      <th>PREVIOUS_AIRPORT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "      <th>DEP_DELAY_NEW</th>\n",
       "      <th>IS_DELAYED</th>\n",
       "      <th>DEP_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>427</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>268</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>2689</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>162</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>143</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>1947</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>199</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>210</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>488</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>541</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>209</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.17</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_MONTH  DAY_OF_WEEK  DEPARTING_AIRPORT  DISTANCE  \\\n",
       "0      1            17            4                 67       427   \n",
       "1      2            27            3                 77      2689   \n",
       "2      8            14            3                 41      1947   \n",
       "3      3            16            6                 51       488   \n",
       "4      6            20            4                 17       541   \n",
       "\n",
       "   SEGMENT_NUMBER  CONCURRENT_FLIGHTS  MANUFACTURE_YEAR  NUMBER_OF_SEATS  \\\n",
       "0               6                  13            2014.0               76   \n",
       "1               2                   3            2002.0              162   \n",
       "2               1                  30            1996.0              199   \n",
       "3               3                  23            2015.0               76   \n",
       "4               4                  24            1998.0              128   \n",
       "\n",
       "   CARRIER_NAME  ...  PLANE_AGE  PREVIOUS_AIRPORT  PRCP  SNOW  SNWD  TMAX  \\\n",
       "0             6  ...          5               268  0.01   0.0   0.0  49.0   \n",
       "1             9  ...         17               143  0.21   0.0   0.0  64.0   \n",
       "2             5  ...         23               210  0.00   0.0   0.0  74.0   \n",
       "3            11  ...          4                64  0.00   0.0   0.0  56.0   \n",
       "4             1  ...         21               209  0.19   0.0   0.0  89.0   \n",
       "\n",
       "    AWND  DEP_DELAY_NEW  IS_DELAYED  DEP_TIME  \n",
       "0   4.70            2.0           1        18  \n",
       "1  12.75            0.0           0        22  \n",
       "2   8.50            0.0           0         6  \n",
       "3  17.67            0.0           0        14  \n",
       "4   9.17           79.0           1        15  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean = dataset.drop(['Id', 'ORIGIN_CITY_NAME', 'DEST_CITY_NAME', 'DEP_TIME_BLK','DEST'], axis = 1)\n",
    "dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DEPARTING_AIRPORT', 'DISTANCE',\n",
       "       'SEGMENT_NUMBER', 'CONCURRENT_FLIGHTS', 'MANUFACTURE_YEAR',\n",
       "       'NUMBER_OF_SEATS', 'CARRIER_NAME', 'AIRPORT_FLIGHTS_MONTH',\n",
       "       'AIRLINE_FLIGHTS_MONTH', 'AIRLINE_AIRPORT_FLIGHTS_MONTH',\n",
       "       'AVG_MONTHLY_PASS_AIRPORT', 'AVG_MONTHLY_PASS_AIRLINE',\n",
       "       'CARGO_HANDLING', 'FLT_ATTENDANTS_PER_PASS', 'GROUND_SERV_PER_PASS',\n",
       "       'PLANE_AGE', 'PREVIOUS_AIRPORT', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'AWND',\n",
       "       'DEP_DELAY_NEW', 'IS_DELAYED', 'DEP_TIME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = dataset_clean.sample(10000)\n",
    "y = X_df['IS_DELAYED'].to_numpy()\n",
    "New_X_df = X_df.drop(['DEP_DELAY_NEW', 'IS_DELAYED'], axis = 1)\n",
    "X = New_X_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 60% training, 20% validation, and 20% testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the remaining data into 50% validation and 50% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 26)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your training data and transform it\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation and test data using the same scaler\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle the training data\n",
    "X_train_normalized, y_train = shuffle(X_train_normalized, y_train, random_state=42)\n",
    "\n",
    "# Shuffle the validation data (if needed)\n",
    "X_val_normalized, y_eval = shuffle(X_val_normalized, y_val, random_state=42)\n",
    "\n",
    "# Shuffle the development data\n",
    "X_dev_normalized, y_dev = shuffle(X_test_normalized, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 50)                1350      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,201\n",
      "Trainable params: 3,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Dense(50, activation='relu', input_shape=(26,)))\n",
    "\n",
    "model_1.add(Dense(30, activation='relu'))\n",
    "\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 9s 39ms/step - loss: 6959.1533 - accuracy: 0.5337 - val_loss: 3223.4482 - val_accuracy: 0.5745\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 3681.3076 - accuracy: 0.5160 - val_loss: 2265.3311 - val_accuracy: 0.4195\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 3491.3286 - accuracy: 0.5188 - val_loss: 4999.8701 - val_accuracy: 0.5530\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 3251.8223 - accuracy: 0.5183 - val_loss: 3197.9038 - val_accuracy: 0.4435\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 3067.6599 - accuracy: 0.5083 - val_loss: 389.6747 - val_accuracy: 0.5440\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 2293.2446 - accuracy: 0.5048 - val_loss: 1644.1494 - val_accuracy: 0.4065\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 2665.0706 - accuracy: 0.5145 - val_loss: 3074.4331 - val_accuracy: 0.4060\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 2153.0442 - accuracy: 0.5098 - val_loss: 463.3811 - val_accuracy: 0.5910\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 1954.1666 - accuracy: 0.5372 - val_loss: 1286.2686 - val_accuracy: 0.5945\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 2018.5774 - accuracy: 0.5353 - val_loss: 759.6113 - val_accuracy: 0.4825\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 520.7562 - accuracy: 0.5678 - val_loss: 0.9133 - val_accuracy: 0.5930\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.7046 - accuracy: 0.5913 - val_loss: 0.6846 - val_accuracy: 0.5945\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.6836 - accuracy: 0.5915 - val_loss: 0.6819 - val_accuracy: 0.5945\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.6814 - accuracy: 0.5915 - val_loss: 0.6798 - val_accuracy: 0.5945\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.6798 - accuracy: 0.5915 - val_loss: 0.6783 - val_accuracy: 0.5945\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.6785 - accuracy: 0.5915 - val_loss: 0.6772 - val_accuracy: 0.5945\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.6777 - accuracy: 0.5915 - val_loss: 0.6764 - val_accuracy: 0.5945\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.6771 - accuracy: 0.5915 - val_loss: 0.6759 - val_accuracy: 0.5945\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.6767 - accuracy: 0.5915 - val_loss: 0.6755 - val_accuracy: 0.5945\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.6765 - accuracy: 0.5915 - val_loss: 0.6753 - val_accuracy: 0.5945\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.6763 - accuracy: 0.5915 - val_loss: 0.6752 - val_accuracy: 0.5945\n",
      "Epoch 22/30\n",
      "175/188 [==========================>...] - ETA: 0s - loss: 0.6755 - accuracy: 0.5936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results1 \u001b[39m=\u001b[39m model_1\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n\u001b[1;32m      2\u001b[0m y_pred_m1 \u001b[39m=\u001b[39m model_1\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      3\u001b[0m y_pred_m1 \u001b[39m=\u001b[39m(y_pred_m1 \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results1 = model_1.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "y_pred_m1 = model_1.predict(X_test)\n",
    "y_pred_m1 =(y_pred_m1 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13 (main, Sep 11 2023, 13:21:10) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "513d186a859c888c0ae87928867d531a5f003b28dc95e180424e2aef27bc2e74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
